from django.core.management.base import BaseCommand
from django.db import transaction
from local_data.models import Location, LocalIssue, RestaurantInfo, SentimentAnalysis, SentimentSummary
from local_data.optimized_crawler import AsyncCrawlerWrapper as LocalIssueCrawler
from local_data.sentiment_analyzer import SimpleSentimentAnalyzer
from django.utils import timezone
import time

class Command(BaseCommand):
    help = 'AWS RDS ì „ì²´ ë°ì´í„° ì‚­ì œ í›„ ëª¨ë“  êµ¬ í¬ë¡¤ë§ ì¬ì‹¤í–‰'

    def add_arguments(self, parser):
        parser.add_argument('--confirm', action='store_true', help='ë°ì´í„° ì‚­ì œ í™•ì¸')
        parser.add_argument('--limit', type=int, default=30, help='êµ¬ë³„ ìˆ˜ì§‘ ê°œìˆ˜')

    def handle(self, *args, **options):
        if not options['confirm']:
            self.stdout.write(
                self.style.WARNING(
                    'âš ï¸  ì´ ëª…ë ¹ì–´ëŠ” AWS RDSì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.\n'
                    'ê³„ì†í•˜ë ¤ë©´ --confirm ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”.'
                )
            )
            return

        self.stdout.write('=== AWS RDS ì „ì²´ ì´ˆê¸°í™” ë° ì¬í¬ë¡¤ë§ ì‹œì‘ ===')
        
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì™„ì „ ì´ˆê¸°í™”
        self.clear_all_data()
        
        # 2. ì„œìš¸ì‹œ 25ê°œ êµ¬ ê¸°ë³¸ ë°ì´í„° ìƒì„±
        self.setup_locations()
        
        # 3. ì „ì²´ êµ¬ í¬ë¡¤ë§ ì‹¤í–‰
        self.crawl_all_districts(options['limit'])
        
        # 4. ìŒì‹ì  ë°ì´í„° í¬ë¡¤ë§
        self.crawl_restaurants()
        
        # 5. ê°ì„± ë¶„ì„ ì‹¤í–‰
        self.analyze_sentiments()
        
        self.stdout.write(
            self.style.SUCCESS('=== AWS RDS ì´ˆê¸°í™” ë° í¬ë¡¤ë§ ì™„ë£Œ ===')
        )

    def clear_all_data(self):
        """ëª¨ë“  í…Œì´ë¸” ë°ì´í„° ì‚­ì œ"""
        self.stdout.write('ğŸ—‘ï¸  ëª¨ë“  ë°ì´í„° ì‚­ì œ ì¤‘...')
        
        with transaction.atomic():
            # ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ìˆœì„œì— ë”°ë¼ ì‚­ì œ
            deleted_sentiment = SentimentAnalysis.objects.all().delete()[0]
            deleted_summary = SentimentSummary.objects.all().delete()[0]
            deleted_issues = LocalIssue.objects.all().delete()[0]
            deleted_restaurants = RestaurantInfo.objects.all().delete()[0]
            deleted_locations = Location.objects.all().delete()[0]
            
            self.stdout.write(
                f'ì‚­ì œëœ ë°ì´í„°: ê°ì„±ë¶„ì„ {deleted_sentiment}ê°œ, '
                f'ìš”ì•½ {deleted_summary}ê°œ, ì´ìŠˆ {deleted_issues}ê°œ, '
                f'ìŒì‹ì  {deleted_restaurants}ê°œ, ì§€ì—­ {deleted_locations}ê°œ'
            )
        
        self.stdout.write(self.style.SUCCESS('âœ… ëª¨ë“  ë°ì´í„° ì‚­ì œ ì™„ë£Œ'))

    def setup_locations(self):
        """ì„œìš¸ì‹œ 25ê°œ êµ¬ ê¸°ë³¸ ë°ì´í„° ìƒì„±"""
        self.stdout.write('ğŸ“ ì§€ì—­ ë°ì´í„° ìƒì„± ì¤‘...')
        
        districts = [
            'ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬', 'ê°•ì„œêµ¬', 'ê´€ì•…êµ¬',
            'ê´‘ì§„êµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ë…¸ì›êµ¬', 'ë„ë´‰êµ¬',
            'ë™ëŒ€ë¬¸êµ¬', 'ë™ì‘êµ¬', 'ë§ˆí¬êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ì„œì´ˆêµ¬',
            'ì„±ë™êµ¬', 'ì„±ë¶êµ¬', 'ì†¡íŒŒêµ¬', 'ì–‘ì²œêµ¬', 'ì˜ë“±í¬êµ¬',
            'ìš©ì‚°êµ¬', 'ì€í‰êµ¬', 'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ì¤‘ë‘êµ¬'
        ]
        
        locations_to_create = []
        for district in districts:
            locations_to_create.append(Location(gu=district))
        
        Location.objects.bulk_create(locations_to_create)
        
        self.stdout.write(
            self.style.SUCCESS(f'âœ… {len(districts)}ê°œ êµ¬ ë°ì´í„° ìƒì„± ì™„ë£Œ')
        )

    def crawl_all_districts(self, limit):
        """ì „ì²´ êµ¬ í¬ë¡¤ë§ ì‹¤í–‰"""
        self.stdout.write(f'ğŸ•·ï¸  ì „ì²´ êµ¬ í¬ë¡¤ë§ ì‹œì‘ (êµ¬ë³„ {limit}ê°œ)')
        
        crawler = LocalIssueCrawler(max_concurrent=5)
        locations = Location.objects.all()
        total_collected = 0
        
        for location in locations:
            self.stdout.write(f'ì²˜ë¦¬ ì¤‘: {location.gu}')
            
            try:
                # í¬ë¡¤ë§ ì‹¤í–‰ (ë” ë§ì€ ì¿¼ë¦¬ë¡œ ì‹œë„)
                results = []
                
                # í¬ë¡¤ë§ ì‹¤í–‰
                results = crawler.crawl_single_district(location.gu, limit)
                
                # ì¤‘ë³µ ì œê±°
                seen_urls = set()
                unique_results = []
                for result in results:
                    if result['url'] not in seen_urls:
                        seen_urls.add(result['url'])
                        unique_results.append(result)
                
                results = unique_results[:limit]
                
                # ë°°ì¹˜ ì €ì¥
                issues_to_create = []
                for result in results:
                    # ì¤‘ë³µ ì²´í¬
                    if LocalIssue.objects.filter(url=result['url']).exists():
                        continue
                    
                    issues_to_create.append(LocalIssue(
                        location=location,
                        source=result['source'],
                        title=result['title'],
                        url=result['url'],
                        view_count=result['view_count'],
                        published_at=result.get('published_at') or timezone.now(),
                        collected_at=timezone.now()
                    ))
                
                # ë°°ì¹˜ INSERT
                if issues_to_create:
                    LocalIssue.objects.bulk_create(
                        issues_to_create, 
                        batch_size=100, 
                        ignore_conflicts=True
                    )
                    saved_count = len(issues_to_create)
                    total_collected += saved_count
                    
                    self.stdout.write(
                        self.style.SUCCESS(f'  âœ… {location.gu}: {saved_count}ê°œ ì €ì¥')
                    )
                else:
                    self.stdout.write(f'  âš ï¸  {location.gu}: ìƒˆë¡œìš´ ë°ì´í„° ì—†ìŒ')
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€
                time.sleep(1)
                
            except Exception as e:
                self.stdout.write(
                    self.style.ERROR(f'  âŒ {location.gu} í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}')
                )
        
        self.stdout.write(
            self.style.SUCCESS(f'âœ… ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: ì´ {total_collected}ê°œ ìˆ˜ì§‘')
        )

    def crawl_restaurants(self):
        """ìŒì‹ì  ë°ì´í„° í¬ë¡¤ë§"""
        self.stdout.write('ğŸ½ï¸  ìŒì‹ì  ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘...')
        
        try:
            from django.core.management import call_command
            call_command('crawl_all_restaurants')
            self.stdout.write(self.style.SUCCESS('âœ… ìŒì‹ì  ë°ì´í„° í¬ë¡¤ë§ ì™„ë£Œ'))
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ ìŒì‹ì  í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}')
            )

    def analyze_sentiments(self):
        """ìˆ˜ì§‘ëœ ë°ì´í„° ê°ì„± ë¶„ì„"""
        self.stdout.write('ğŸ§  ê°ì„± ë¶„ì„ ì‹œì‘...')
        
        # ê°ì„± ë¶„ì„ì´ ì—†ëŠ” ì´ìŠˆë“¤ ì¡°íšŒ
        analyzed_ids = SentimentAnalysis.objects.filter(
            content_type='local_issue'
        ).values_list('content_id', flat=True)
        
        issues = LocalIssue.objects.exclude(
            id__in=analyzed_ids
        )[:1000]  # ìµœëŒ€ 1000ê°œ
        
        if not issues.exists():
            self.stdout.write('ë¶„ì„í•  ìƒˆë¡œìš´ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.')
            return
        
        analyzer = SimpleSentimentAnalyzer()
        analyses_to_create = []
        
        for issue in issues:
            try:
                result = analyzer.analyze_text(issue.title)
                
                analyses_to_create.append(SentimentAnalysis(
                    location=issue.location,
                    content_type='local_issue',
                    content_id=issue.id,
                    sentiment=result['sentiment'],
                    confidence=result['confidence'],
                    keywords=result.get('keywords', [])
                ))
                
                # ë°°ì¹˜ í¬ê¸° ì œí•œ
                if len(analyses_to_create) >= 100:
                    SentimentAnalysis.objects.bulk_create(
                        analyses_to_create, 
                        ignore_conflicts=True
                    )
                    analyses_to_create = []
                    
            except Exception as e:
                continue
        
        # ë‚¨ì€ ë°ì´í„° ì €ì¥
        if analyses_to_create:
            SentimentAnalysis.objects.bulk_create(
                analyses_to_create, 
                ignore_conflicts=True
            )
        
        analyzed_count = SentimentAnalysis.objects.count()
        self.stdout.write(
            self.style.SUCCESS(f'âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ: {analyzed_count}ê°œ ë¶„ì„')
        )